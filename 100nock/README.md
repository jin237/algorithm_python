# 言語処理１００本ノック２０２０（Rev 1）
https://nlp100.github.io/ja/

# 第01章：準備運動
https://nlp100.github.io/ja/ch01.html

list[
00. 文字列の逆順
01. 「パタトクカシーー」
02. 「パトカー」＋「タクシー」＝「パタトクカシーー」
03. 円周率
04. 元素記号
05. n-gram
06. 集合
07. テンプレートによる文生成
08. 暗号文
09. Typoglycemia
]

### 00. 文字列の逆順Permalink
文字列”stressed”の文字を逆に（末尾から先頭に向かって）並べた文字列を得よ．

### 01. 「パタトクカシーー」Permalink
「パタトクカシーー」という文字列の1,3,5,7文字目を取り出して連結した文字列を得よ．

### 02. 「パトカー」＋「タクシー」＝「パタトクカシーー」Permalink
「パトカー」＋「タクシー」の文字を先頭から交互に連結して文字列「パタトクカシーー」を得よ．

### 03. 円周率Permalink
“Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.”という文を単語に分解し，各単語の（アルファベットの）文字数を先頭から出現順に並べたリストを作成せよ．

### 04. 元素記号Permalink
“Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.”という文を単語に分解し，1, 5, 6, 7, 8, 9, 15, 16, 19番目の単語は先頭の1文字，それ以外の単語は先頭の2文字を取り出し，取り出した文字列から単語の位置（先頭から何番目の単語か）への連想配列（辞書型もしくはマップ型）を作成せよ．

### 05. n-gramPermalink
与えられたシーケンス（文字列やリストなど）からn-gramを作る関数を作成せよ．この関数を用い，”I am an NLPer”という文から単語bi-gram，文字bi-gramを得よ．

### 06. 集合Permalink
“paraparaparadise”と”paragraph”に含まれる文字bi-gramの集合を，それぞれ, XとYとして求め，XとYの和集合，積集合，差集合を求めよ．さらに，’se’というbi-gramがXおよびYに含まれるかどうかを調べよ．

### 07. テンプレートによる文生成Permalink
引数x, y, zを受け取り「x時のyはz」という文字列を返す関数を実装せよ．さらに，x=12, y=”気温”, z=22.4として，実行結果を確認せよ．

### 08. 暗号文Permalink
与えられた文字列の各文字を，以下の仕様で変換する関数cipherを実装せよ．

英小文字ならば(219 - 文字コード)の文字に置換
その他の文字はそのまま出力
この関数を用い，英語のメッセージを暗号化・復号化せよ．

### 09. TypoglycemiaPermalink
スペースで区切られた単語列に対して，各単語の先頭と末尾の文字は残し，それ以外の文字の順序をランダムに並び替えるプログラムを作成せよ．ただし，長さが４以下の単語は並び替えないこととする．適当な英語の文（例えば”I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind .”）を与え，その実行結果を確認せよ．

# 第02章：UNIXコマンド
https://nlp100.github.io/ja/ch02.html

list[
10. 行数のカウント
11. タブをスペースに置換
12. 1列目をcol1.txtに，2列目をcol2.txtに保存
13. col1.txtとcol2.txtをマージ
14. 先頭からN行を出力
15. 末尾のN行を出力
16. ファイルをN分割する
17. １列目の文字列の異なり
18. 各行を3コラム目の数値の降順にソート
19. 各行の1コラム目の文字列の出現頻度を求め，出現頻度の高い順に並べる
]

### 10. 行数のカウントPermalink
行数をカウントせよ．確認にはwcコマンドを用いよ．

### 11. タブをスペースに置換Permalink
タブ1文字につきスペース1文字に置換せよ．確認にはsedコマンド，trコマンド，もしくはexpandコマンドを用いよ．

### 12. 1列目をcol1.txtに，2列目をcol2.txtに保存Permalink
各行の1列目だけを抜き出したものをcol1.txtに，2列目だけを抜き出したものをcol2.txtとしてファイルに保存せよ．確認にはcutコマンドを用いよ．

### 13. col1.txtとcol2.txtをマージPermalink
12で作ったcol1.txtとcol2.txtを結合し，元のファイルの1列目と2列目をタブ区切りで並べたテキストファイルを作成せよ．確認にはpasteコマンドを用いよ．

### 14. 先頭からN行を出力Permalink
自然数Nをコマンドライン引数などの手段で受け取り，入力のうち先頭のN行だけを表示せよ．確認にはheadコマンドを用いよ．

### 15. 末尾のN行を出力Permalink
自然数Nをコマンドライン引数などの手段で受け取り，入力のうち末尾のN行だけを表示せよ．確認にはtailコマンドを用いよ．

### 16. ファイルをN分割するPermalink
自然数Nをコマンドライン引数などの手段で受け取り，入力のファイルを行単位でN分割せよ．同様の処理をsplitコマンドで実現せよ．

### 17. １列目の文字列の異なりPermalink
1列目の文字列の種類（異なる文字列の集合）を求めよ．確認にはcut, sort, uniqコマンドを用いよ．

### 18. 各行を3コラム目の数値の降順にソートPermalink
各行を3コラム目の数値の逆順で整列せよ（注意: 各行の内容は変更せずに並び替えよ）．確認にはsortコマンドを用いよ（この問題はコマンドで実行した時の結果と合わなくてもよい）．

### 19. 各行の1コラム目の文字列の出現頻度を求め，出現頻度の高い順に並べるPermalink
各行の1列目の文字列の出現頻度を求め，その高い順に並べて表示せよ．確認にはcut, uniq, sortコマンドを用いよ．

# 第03章：正規表現
https://nlp100.github.io/ja/ch03.html

list[
20. JSONデータの読み込み
21. カテゴリ名を含む行を抽出
22. カテゴリ名の抽出
23. セクション構造
24. ファイル参照の抽出
25. テンプレートの抽出
26. 強調マークアップの除去
27. 内部リンクの除去
28. MediaWikiマークアップの除去
29. 国旗画像のURLを取得する
]

### 20. JSONデータの読み込みPermalink
Wikipedia記事のJSONファイルを読み込み，「イギリス」に関する記事本文を表示せよ．問題21-29では，ここで抽出した記事本文に対して実行せよ．

### 21. カテゴリ名を含む行を抽出Permalink
記事中でカテゴリ名を宣言している行を抽出せよ．

### 22. カテゴリ名の抽出Permalink
記事のカテゴリ名を（行単位ではなく名前で）抽出せよ．

### 23. セクション構造Permalink
記事中に含まれるセクション名とそのレベル（例えば”== セクション名 ==”なら1）を表示せよ．

### 24. ファイル参照の抽出Permalink
記事から参照されているメディアファイルをすべて抜き出せ．

### 25. テンプレートの抽出Permalink
記事中に含まれる「基礎情報」テンプレートのフィールド名と値を抽出し，辞書オブジェクトとして格納せよ．

### 26. 強調マークアップの除去Permalink
25の処理時に，テンプレートの値からMediaWikiの強調マークアップ（弱い強調，強調，強い強調のすべて）を除去してテキストに変換せよ（参考: マークアップ早見表）．

### 27. 内部リンクの除去Permalink
26の処理に加えて，テンプレートの値からMediaWikiの内部リンクマークアップを除去し，テキストに変換せよ（参考: マークアップ早見表）．

### 28. MediaWikiマークアップの除去Permalink
27の処理に加えて，テンプレートの値からMediaWikiマークアップを可能な限り除去し，国の基本情報を整形せよ．

### 29. 国旗画像のURLを取得するPermalink
テンプレートの内容を利用し，国旗画像のURLを取得せよ．（ヒント: MediaWiki APIのimageinfoを呼び出して，ファイル参照をURLに変換すればよい）

# 第04章：形態素解析
https://nlp100.github.io/ja/ch04.html

# 第05章：係り受け解析
https://nlp100.github.io/ja/ch05.html

# 第06章：機械学習
https://nlp100.github.io/ja/ch06.html

# 第07章：単語ベクトル
https://nlp100.github.io/ja/ch07.html

# 第08章：ニューラルネットワーク
https://nlp100.github.io/ja/ch08.html

# 第09章：RNNとCNN
https://nlp100.github.io/ja/ch09.html

# 第10章：機械翻訳
https://nlp100.github.io/ja/ch10.html
